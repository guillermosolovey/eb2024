{
  "hash": "4735a7f7e7f4a0d30e4d0fd0ff82a570",
  "result": {
    "markdown": "---\ntitle: \"Estimación bayesiana\"\nsubtitle: \"intervalos de confianza (F) vs. intervalo de credibilidad (B)\"\nformat: \n  html:\n    toc: true\n    df-print: paged\neditor: source\n---\n\n\nUna máquina funciona perfectamente mientras tiene una sustancia que la protege. Sin embargo, esta sustancia se va consumiendo y cuando se agota, después de un tiempo $\\theta$, puede fallar en algún momento aleatorio que sigue una distribución exponencial. El tiempo que pasa hasta que produce la falla,$x$, sigue una distribución exponencial truncada dada por:\n\n$$ \nf(x|\\theta) = \\left\\{\n\\begin{array}{ll}\n      0 & x < \\theta \\\\\n      e^{-(x-\\theta)} & x > \\theta \\\\\n\\end{array} \n\\right. \n$$\n\nSe mide el tiempo de falla de tres máquinas obteniendo: $\\text{datos} = \\{10,12,15\\}$. El objetivo es, a partir de estos datos, inferir $\\theta$. En particular, queremos un intervalo de confianza frecuentista y un intervalo de credibilidad bayesiano para $\\theta$.\n\n## Intervalo frecuentista\n\nEl intervalo de confianza asintótico para un estimador $\\theta$ es $\\text{CI}_{95} \\approx \\hat{\\theta} \\pm 2~\\sqrt{\\mathbb{V}(\\hat{\\theta})}$. Observando que $y = x - \\theta$ es exponencial con parámetro 1, la esperanza de $y$ es $E(y)=1$ y la varianza $\\mathbb{V}(y)=1$, para $x$ tenemos:\n\n$$\n\\begin{array}{l}\nE(x) = \\theta + 1 \\\\\n\\mathbb{V}(x) = \\mathbb{V}(y+\\theta) = 1\n\\end{array} \n$$\n\nPor lo tanto, un estimador de $\\theta$ es:\n\n$$ \n\\hat{\\theta} = \\frac{1}{N} \\sum_{i=1}^N x_i - 1 \\\\\n$$\n que tiene una varianza $\\mathbb{V}(\\hat{\\theta}) = \\frac{1}{N^2} \\sum \\mathbb{V}(x_i) = \\frac{1}{N}$. Por lo tanto, el intervalo de confianza del 95% asintótico es:\n\n$$\n\\text{CI}_{95} \\approx (\\hat{\\theta} - 2 / \\sqrt{N}, \\hat{\\theta} + 2 / \\sqrt{N}) \\\\\n$$\n\nUsando los  $\\text{datos} = \\{10,12,15\\}$, obtenemos que:\n\n$$\n\\begin{array}{ll}\n\\color{blue}{ \\hat{\\theta}   } & \\color{blue}{ \\approx 11.3 } \\\\\n\\color{blue}{ \\text{CI}_{95} } & \\color{blue}{ \\approx (10.2, 12.5) }\n\\end{array} \n$$\n\nEste intervalo de confianza llama la atención porque claramente $\\theta$, el tiempo a partir del cual la máquina comienza a fallar no puede ser mayor que el mínimo entre todos los tiempos de falla que se midieron. O sea: $\\theta <10$!!\n\n## Intervalo bayesiano\n\nTenemos que encontrar la distribución de probabilidad posterior $P(\\theta|\\text{datos})$:\n\n$$\n\\require{mathtools}\n\\definecolor{bayesred}{RGB}{147, 30, 24}\n\\definecolor{bayesblue}{RGB}{32, 35, 91}\n\\definecolor{bayesorange}{RGB}{218, 120, 1}\n\\definecolor{grey}{RGB}{128, 128, 128}\n\\color{bayesorange} \\overbracket[0.25pt]{P(\\theta \\mid \\text{datos})}^{\\text{Posterior}} \\sim\n\\color{bayesred}    \\overbracket[0.25pt]{P(\\theta)}^{\\text{Prior}} \\times \n\\color{bayesblue}   \\overbracket[0.25pt]{P(\\text{datos} \\mid \\theta)}^{\\text{Likelihood}}\n$$\nComo prior vamos a usar una distribución uniforme entre 0 y algún número elevado $\\theta_{max}$ que sea superior a cualquier tiempo de falla razonable (por ejemplo $\\theta_{max}=10^{10}$). El likelihood es:\n\n$$\n\\begin{array}{ll}\nL(\\theta) & = P(\\text{datos} \\mid \\theta) = \\prod_{i=1}^{N} f(x_i \\mid \\theta) \\\\\n& \\sim \\left\\{ \\begin{array}{ll}\n      \\exp(N\\theta) & \\theta < \\text{min}(x_i) \\\\\n      0             & \\theta > \\text{min}(x_i) \n\\end{array} \n\\right. \n\\end{array}\n$$\n\nPor lo tanto, la distribución posterior es:\n\n$$\n\\definecolor{bayesorange}{RGB}{218, 120, 1}\n\\color{bayesorange}{P(\\theta \\mid \\text{datos})} \n\\sim \\left\\{ \\begin{array}{ll}\n      e^{3\\theta} & 0 < \\theta < 10 \\\\\n      0             & \\theta > 10\n\\end{array} \n\\right. \n$$\nAhora, un intervalo del 95% de credibilidad para $\\theta$ es un intervalo $(a,10)$ tal que\n\n$$\n\\frac{\\int_a^{10} e^{3\\theta} ~  d\\theta }{\\int_0^{10} e^{3\\theta} ~  d\\theta } = 0.95\n$$\n\nHaciendo la cuenta se obtiene que $a=9$ y por lo tanto, **condicional al modelo y a los datos**, podemos afirmar que existe una probabilidad del 95% de que el tiempo en el cual se agota el líquido necesario para que funcione la máquina, $\\theta$, esté entre 9 y 10.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](intervalos_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n\n::: callout-important\n## Recordar\n\nUn intervalo de confianza no es una afirmación probabilística sobre $\\theta$.\n:::\n\n\n\n## ¿Funciona mal el intervalo frecuentista?\n\n¿Por qué el intervalo frecuentista queda enteramente por afuera de la región aceptable para el parámetro $\\theta$? El intervalo de confianza frecuentista, por definición, contiene al parámetro verdadero con una probabilidad del 95%. Esto quiere decir que si tomamos muchas muestras de tamaño 3 (como en este problema) y para cada muestra aleatoria calculamos el intervalo de confianza, el 95% van a incluir al verdadero. Lo que ocurre con estos datos es que por mala suerte nos tocó uno de los intervalos de ese 5% que no contiene al verdadero.\n\nVerifiquemos que el intervalo de confianza asintótico funciona bien. Al ser asintótico, debería ser correcto para un tamaño de muestra grande, pero en este caso $n=3$ y podría no ser válido como intervalo de confianza. Para ver si es el caso, vamos a simular muchas muestras aleatorias de $n=3$ para un parámetro $\\theta=10$ fijo y para cada una vamos a verificar si el intervalo de confianza contiene al valor verdadero.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn     = 3\ntheta = 10\n\nNit = 10000\nok  = 0\nfor (i in 1:Nit){\n\n  x     = rexp(n, 1) + theta\n  theta.e = mean(x) - 1\n  ci      = c(theta.e - 2/sqrt(n), theta.e + 2/sqrt(n))\n  \n  if (theta > ci[1] & theta < ci[2]){\n    ok = ok + 1\n  }\n}\n\n# cobertura del intervalo de confianza\nprint(ok/Nit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.951\n```\n:::\n:::\n\n\nDe las 10.000 muestras aleatorias con $N=3$ simuladas alrededor del 95% contiene al parámetro $\\theta=10$. \n\n## Problema \n\nOriginalmente planteado por Berger y Wolpert (1984), yo lo tomé del libro de Wasserman \"All of Statistics\" (¡excelente!).\n\nSupongamos que hay dos variables aleatorias $X_1$ y $X_2$ independientes que pueden tomar el valor 1 o -1 con igual probabilidad (¡dos monedas!). Definimos otras dos variables así:\n\n$$\n\\begin{array}{ll}\nY_1 &= \\theta + X_1 \\\\\nY_2 &= \\theta + X_2\n\\end{array}\n$$\nSupongamos que sólo se miden $Y_1$ e $Y_2$ y se quiere estimar $\\theta$ que está fijo.\n\n1- Verificar que $C$, definido a continuación, es un intervalo de confianza del 75% para $\\theta$:\n\n\n$$ \nC = \\left\\{\n\\begin{array}{ll}\n      Y_1 - 1        & \\text{si } Y_1 = Y_2 \\\\\n      (Y_1 + Y_2)/2  & \\text{si } Y_1 \\ne Y_2 \n\\end{array} \n\\right. \n$$\n\n2- Supongan ahora que se mide en un experimento $y_1 = 15$ y $y_2=17$, ¿cuál es el intervalo de confianza del 75% para $\\theta$? ¿cuánto vale $\\theta$? \n",
    "supporting": [
      "intervalos_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}